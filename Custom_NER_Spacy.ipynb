{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in /mnt/workspace/.local/lib/python3.5/site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /mnt/workspace/.local/lib/python3.5/site-packages (from bs4) (4.8.1)\n",
      "Requirement already satisfied: soupsieve>=1.2 in /mnt/workspace/.local/lib/python3.5/site-packages (from beautifulsoup4->bs4) (1.9.5)\n",
      "\u001b[33mYou are using pip version 18.0, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "#!pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.0/en_core_web_sm-2.2.0.tar.gz --user\n",
    "nlp = en_core_web_sm.load()\n",
    "import pandas as pd\n",
    "import json\n",
    "!pip install bs4 --user\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "import mmap\n",
    "import random\n",
    "from spacy.gold import GoldParse\n",
    "from spacy.scorer import Scorer\n",
    "from spacy.util import minibatch, compounding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-I need to book a train that leaves after 08:45 on Sunday\n",
      "1-I can help!  Where are you traveling to?\n",
      "2-I'll be traveling to Cambridge and want to depart from Birmingham New Street. What are my options?\n",
      "3-The TR9714 leaves at 09:40. \n",
      "4-Can you please provide me with the arrival and travel time? Thank you\n",
      "5-The arrival time is 12:23, and it's a long trip - 163 minutes. Can I help you with anything else today?\n",
      "6-Yes I am looking for colleges to visit in town.\n",
      "7-Okay, there are 18 in town! What part of town would you like to go to?\n",
      "8-Whichever one wherever you like best please. \n",
      "9-I personally like to visit Christ's College myself.  And, it's free to enter.  Would that work for you?\n",
      "10-That sounds great.  Can you give me the address and phone number?\n",
      "11-Their address is saint andrew's street, and their phone number 01223334900.\n",
      "12-Great, thanks so much, that's all that I need!\n",
      "13-Thank you so much for calling Cambridge TownInfo centre! It was a pleasure to serve you, we hope you enjoy your trip!\n"
     ]
    }
   ],
   "source": [
    "with open('data.json', 'r') as f:\n",
    "    dict_json_weighted = json.load(f)\n",
    "object_1 = list(dict_json_weighted.keys())[2]\n",
    "for i in range(len(dict_json_weighted[object_1]['log'])):\n",
    "    print(str(i)+\"-\"+dict_json_weighted[object_1]['log'][i]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ontology.json', 'r') as o:\n",
    "    ontology = json.load(o)\n",
    "    my_ent=list(ontology.keys())\n",
    "    \n",
    "    \n",
    "action=['inform', 'request', 'select', 'recommend', 'not found', 'request booking', 'offer booking', \n",
    "        'inform booked', 'decline booking', 'welcome','greet', 'bye', 'reqmore' ]\n",
    "topic= ['hotel', 'restaurant', 'taxi', 'train', 'attraction', 'police', 'hospital']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## display topics and actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topics: ['train']\n",
      "actions: []\n"
     ]
    }
   ],
   "source": [
    "top=[]\n",
    "act=[]\n",
    "ont=list(ontology.keys())\n",
    "for i in range(len(dict_json_weighted[object_1]['log'])):\n",
    "    #print(dict_json_weighted[object_1]['log'][i]['text'])\n",
    "    sentence =nlp (dict_json_weighted[object_1]['log'][i]['text'])\n",
    "    for x in [y for y in sentence if y.pos_ != 'PUNCT']:\n",
    "        if str(x).lower() in topic:\n",
    "            if str(x).lower() not in top:\n",
    "                top.append(str(x).lower()) \n",
    "        if x.lemma_ in action:\n",
    "            if x.lemma_ not in act:\n",
    "                act.append(x.lemma_)\n",
    "        #for z in ont:\n",
    "            #if str(x) in str(ontology[z]):\n",
    "                #print(z+\" :\"+str(x))           \n",
    "print(\"topics: \"+str(top))\n",
    "print(\"actions: \"+str(act))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the updated slots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** attraction ******\n",
      "°reqt\n",
      "['address', 'phone']\n",
      "°info\n",
      "{'type': 'college'}\n",
      "****** train ******\n",
      "°reqt\n",
      "['trainID', 'arriveBy', 'duration']\n",
      "°info\n",
      "{'destination': 'cambridge', 'leaveAt': '08:45', 'departure': 'birmingham new street', 'day': 'sunday'}\n"
     ]
    }
   ],
   "source": [
    "for i in dict_json_weighted[object_1]['goal']:\n",
    "    if i not in['message', 'topic']:\n",
    "        if dict_json_weighted[object_1]['goal'][i] !={}:\n",
    "            print(\"****** \"+i+\" ******\")\n",
    "            for j in (dict_json_weighted[object_1]['goal'][i]):\n",
    "                if dict_json_weighted[object_1]['goal'][i][j] not in ['fail_info', {}]:\n",
    "                    print(\"°\"+j)\n",
    "                    print(dict_json_weighted[object_1]['goal'][i][j])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create training sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_data = [\n",
    "     (\n",
    "        \"Hello, I am looking for a cheap place to dine in the centre\", { \"entities\" :\n",
    "        [(26, 19, \"restaurant-price-range\"), (46, 5, \"restaurant-area\")]\n",
    "        }\n",
    "    ),(\n",
    "        \"not really but i need it for 3 people\",  { \"entities\" : \n",
    "        [(29, 8, \"restaurant-book-people\")]\n",
    "        }\n",
    "    ),(\n",
    "        \"I recommend La Raza - fantastic (and cheap!) Spanish cuisine. I'd be happy to book a table for you, if you like.\",  { \"entities\" : \n",
    "        [(12, 7, \"restaurant-name\"), (46, 15, \"restaurant-food\")]\n",
    "        }\n",
    "\n",
    "    ),(\n",
    "        \"Yes for 3 at 14:45 wednesday, can I get the reference number too please\", \n",
    "        { \"entities\" :\n",
    "        [(8, 1, \"restaurant-book-people\"), (13, 5, \"restaurant-book-time\"), (19, 9, \"restaurant-book-day\")]\n",
    "        }\n",
    "    ),( \n",
    "        \"Both offer free parking and free wifi. The Alexander B&B is 4 star rated. The El Shaddai has a 0 rating.\", { \"entities\" : \n",
    "             [(11, 12, \"hotel-parking\"), (28, 9, \"hotel-internet\"), (39, 17, \"hotel-name\"), (60, 6, \"hotel-stars\"), (78, 11, \"hotel-name\"), (96, 8, \"hotel-stars\")]\n",
    "             }\n",
    "    ),( \n",
    "        \"3 nights, 3 people, please.\", { \"entities\" : \n",
    "             [(0, 8, \"hotel-book-stay\"), (10, 8, \"hotel-book-people\")]\n",
    "             }\n",
    "    ),( \n",
    "        \"I would like a taxi from the hotel to the restaurant. I would like to arrive by 14:45. I would like the contact number and car type\",  { \"entities\" : \n",
    "             [(77, 5, \"taxi-arrive-by\")]\n",
    "             }\n",
    "    ),( \n",
    "        \"Thanks. I also need a cheap place to stay in the center.\", { \"entities\" : \n",
    "             [(22, 19, \"hotel-price-range\"),(43, 13, \"hotel-area\")]\n",
    "             }\n",
    "    ),( \n",
    "        \"I am looking for info about a hotel called city centre north b and b. Can you help?\", { \"entities\" : \n",
    "             [(40, 25, \"hotel-name\")]\n",
    "             }\n",
    "    ),( \n",
    "        \"Yes. City Centre North B and B is a guesthouse in the north side of town, that has both free internet and parking. Do you want to book a room?\", { \"entities\" : \n",
    "             [(33, 10, \"hotel-type\"),(44, 25, \"hoyel-area\")]\n",
    "             }\n",
    "    ),( \n",
    "        \"Ok, I am also looking for a train from Cambridge to Bishops Stortford.\", { \"entities\" : \n",
    "             [(33, 14, \"train-departure\"),(47, 20, \"train-destination\")]\n",
    "             }\n",
    "    ),( \n",
    "        \"I'll be leaving Monday after 15:30.\", { \"entities\" : \n",
    "             [(16, 5, \"train-day\"),(23, 11, \"train-leave-at\")]\n",
    "             }\n",
    "    ),( \n",
    "        \"TR2630 leaves at 17:29. Would you like for me to book the train for you?\", { \"entities\" : \n",
    "             [(14, 8, \"train-leave-at\")]\n",
    "             }\n",
    "    ),( \n",
    "        \"Yes I would like to book the train for 4 people and I'll need the reference number please.\", { \"entities\" : \n",
    "             [(23, 8, \"train-book-people\")]\n",
    "             }\n",
    "    ),( \n",
    "        \"I'm looking for a Mediterranean restaurant near the centre of town.\", { \"entities\" : \n",
    "             [(18, 24, \"restaurant-food\"), (41, 23, \"restaurant-area\")]\n",
    "             }\n",
    "    ),( \n",
    "        \"I've got three that fit that bill... the gardenia, la mimosa, and shiraz.  Do you have a preference?\", { \"entities\" : \n",
    "             [(26, 16, \"restaurant-name\"),(39, 11, \"restaurant-name\"),(54, 5, \"restaurant-name\")]\n",
    "             }\n",
    "    ),( \n",
    "        \"Great, could I book a table of 5 for 11:30 on wednesday? If so, please provide me with a reference number\", { \"entities\" : \n",
    "             [(13, 12, \"resraurant-book-people\"),(29, 5, \"restaurant-book-time\"),(38, 9, \"restaurant-bookday\")]\n",
    "             }\n",
    "    ),( \n",
    "        \"Is one of them in the cheap price range? \", { \"entities\" : \n",
    "             [(22, 5, \"restaurant-price-range\")]\n",
    "             }\n",
    "    ),( \n",
    "        \"Yes. Can you please search for an attraction in the type of college?\", { \"entities\" : \n",
    "             [(45, 15, \"attraction-type\")]\n",
    "             }\n",
    "    ),( \n",
    "        \"Is an entrance fee okay? If so, the corpus christi college located at king's parade. Fee is 2 pounds. Would you like the phone number? \", { \"entities\" : \n",
    "             [(32, 26, \"attraction-name\")]\n",
    "             }\n",
    "    ),( \n",
    "        \"I would like to leave Corpus Christi College in enough time to arrive at the restaurant at the booked time of 11:30. \", { \"entities\" : \n",
    "             [(22, 21, \"train-departure\"), (81, 20, \"train-arrive-by\")]\n",
    "             }\n",
    "    ),( \n",
    "        \"I'm looking for a place to stay in Cambridge. It should include free wifi and be a 3 star.  Can you help me please? \", { \"entities\" : \n",
    "             [(62, 9, \"hotel-internet\"), (80, 6, \"hotel-stars\")]\n",
    "             }\n",
    "    ),( \n",
    "        \"There are five to choose from. Would you like moderate or expensive price point? \", { \"entities\" : \n",
    "             [(45, 8, \"hotel-price-range\"), (57, 9, \"hotel-price-range\")]\n",
    "             }\n",
    "    ),( \n",
    "        \"I have the gonville hotel. It is expensive. Would you like me to book that for you?\", { \"entities\" : \n",
    "             [(7, 12, \"hotel-name\"), (31, 9, \"hotel-price-range\")]\n",
    "             }\n",
    "    ),( \n",
    "        \"Do they have free parking? If so, please reserve a room for Tuesday for 7 people, 4 nights.\", { \"entities\" : \n",
    "             [(13, 12, \"hotel-parking\"), (55, 7, \"hotel-book-day\"), (67, 8, \"hotel-book-people\"), (77,8, \"hotel-book-stay\")]\n",
    "             }\n",
    "    ),\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'en' model\n",
      "Starting iteration0\n",
      "Losses {'ner': 465.93111550807953}\n",
      "Starting iteration1\n",
      "Losses {'ner': 159.95644586162763}\n",
      "Starting iteration2\n",
      "Losses {'ner': 1.9939078390485754}\n",
      "Starting iteration3\n",
      "Losses {'ner': 1.999998808135351}\n",
      "Starting iteration4\n",
      "Losses {'ner': 1.9999989271165997}\n",
      "Starting iteration5\n",
      "Losses {'ner': 1.9998061656968886}\n",
      "Starting iteration6\n",
      "Losses {'ner': 1.5467722900900993}\n",
      "Starting iteration7\n",
      "Losses {'ner': 11.472626180973483}\n",
      "Starting iteration8\n",
      "Losses {'ner': 3.027851985903351}\n",
      "Starting iteration9\n",
      "Losses {'ner': 1.3883270726457047}\n",
      "Starting iteration10\n",
      "Losses {'ner': 1.4310926443135628}\n",
      "Starting iteration11\n",
      "Losses {'ner': 0.93889004149102}\n",
      "Starting iteration12\n",
      "Losses {'ner': 1.9130931295428502}\n",
      "Starting iteration13\n",
      "Losses {'ner': 0.6867917114436607}\n",
      "Starting iteration14\n",
      "Losses {'ner': 11.848349512909158}\n",
      "Starting iteration15\n",
      "Losses {'ner': 0.7756770687846517}\n",
      "Starting iteration16\n",
      "Losses {'ner': 2.307178115092704}\n",
      "Starting iteration17\n",
      "Losses {'ner': 1.7828242349811068}\n",
      "Starting iteration18\n",
      "Losses {'ner': 0.9951478826687619}\n",
      "Starting iteration19\n",
      "Losses {'ner': 0.8972021067422554}\n",
      "Starting iteration20\n",
      "Losses {'ner': 0.6028974380325531}\n",
      "Starting iteration21\n",
      "Losses {'ner': 2.005073592740894}\n",
      "Starting iteration22\n",
      "Losses {'ner': 0.012040713275913544}\n",
      "Starting iteration23\n",
      "Losses {'ner': 0.029822032156575168}\n",
      "Starting iteration24\n",
      "Losses {'ner': 8.450875050431566e-06}\n",
      "Starting iteration25\n",
      "Losses {'ner': 4.5717450334271e-05}\n",
      "Starting iteration26\n",
      "Losses {'ner': 1.0857023023482715e-06}\n",
      "Starting iteration27\n",
      "Losses {'ner': 2.4933814585010865e-06}\n",
      "Starting iteration28\n",
      "Losses {'ner': 1.260163604553199e-06}\n",
      "Starting iteration29\n",
      "Losses {'ner': 5.362541021642474e-06}\n",
      "Starting iteration30\n",
      "Losses {'ner': 2.8949619377703044e-08}\n",
      "Starting iteration31\n",
      "Losses {'ner': 1.3910342097866948e-06}\n",
      "Starting iteration32\n",
      "Losses {'ner': 5.109356116677866e-09}\n",
      "Starting iteration33\n",
      "Losses {'ner': 4.839976999203183e-07}\n",
      "Starting iteration34\n",
      "Losses {'ner': 4.4099868498788985e-08}\n",
      "Starting iteration35\n",
      "Losses {'ner': 5.787780938186108e-09}\n",
      "Starting iteration36\n",
      "Losses {'ner': 9.590953833126828e-07}\n",
      "Starting iteration37\n",
      "Losses {'ner': 2.0819399295978776e-09}\n",
      "Starting iteration38\n",
      "Losses {'ner': 0.0038822188417717415}\n",
      "Starting iteration39\n",
      "Losses {'ner': 5.2924058802094335e-05}\n",
      "Starting iteration40\n",
      "Losses {'ner': 2.1584925929616843e-06}\n",
      "Starting iteration41\n",
      "Losses {'ner': 3.6608450296273765e-06}\n",
      "Starting iteration42\n",
      "Losses {'ner': 6.821120203190908e-05}\n",
      "Starting iteration43\n",
      "Losses {'ner': 5.023574402106218e-09}\n",
      "Starting iteration44\n",
      "Losses {'ner': 5.503356867936916e-07}\n",
      "Starting iteration45\n",
      "Losses {'ner': 2.0393994056852533e-09}\n",
      "Starting iteration46\n",
      "Losses {'ner': 8.836602625810768e-11}\n",
      "Starting iteration47\n",
      "Losses {'ner': 1.1298475575778668e-09}\n",
      "Starting iteration48\n",
      "Losses {'ner': 8.954847753447485e-11}\n",
      "Starting iteration49\n",
      "Losses {'ner': 7.326342757585455e-10}\n",
      "Starting iteration50\n",
      "Losses {'ner': 7.164945557109227e-10}\n",
      "Starting iteration51\n",
      "Losses {'ner': 1.3826865225994786e-07}\n",
      "Starting iteration52\n",
      "Losses {'ner': 1.14776250906846e-10}\n",
      "Starting iteration53\n",
      "Losses {'ner': 2.631927498778829e-07}\n",
      "Starting iteration54\n",
      "Losses {'ner': 1.3107571969312777e-08}\n",
      "Starting iteration55\n",
      "Losses {'ner': 5.905874905387135e-09}\n",
      "Starting iteration56\n",
      "Losses {'ner': 1.6014848961905695e-08}\n",
      "Starting iteration57\n",
      "Losses {'ner': 9.639909353552472e-09}\n",
      "Starting iteration58\n",
      "Losses {'ner': 4.4547915094564524e-11}\n",
      "Starting iteration59\n",
      "Losses {'ner': 5.2761204525608955e-08}\n",
      "Starting iteration60\n",
      "Losses {'ner': 2.1448796616819295e-12}\n",
      "Starting iteration61\n",
      "Losses {'ner': 2.723021256119581e-08}\n",
      "Starting iteration62\n",
      "Losses {'ner': 1.9169704849853277e-09}\n",
      "Starting iteration63\n",
      "Losses {'ner': 1.1094526215209655e-09}\n",
      "Starting iteration64\n",
      "Losses {'ner': 6.8570228451461294e-09}\n",
      "Starting iteration65\n",
      "Losses {'ner': 6.908833321144683e-10}\n",
      "Starting iteration66\n",
      "Losses {'ner': 2.0972846062819432e-07}\n",
      "Starting iteration67\n",
      "Losses {'ner': 4.896969232111411e-07}\n",
      "Starting iteration68\n",
      "Losses {'ner': 3.6517910818678706e-08}\n",
      "Starting iteration69\n",
      "Losses {'ner': 2.2048971171531138e-07}\n",
      "Starting iteration70\n",
      "Losses {'ner': 6.843990492791439e-11}\n",
      "Starting iteration71\n",
      "Losses {'ner': 5.084022609019694e-10}\n",
      "Starting iteration72\n",
      "Losses {'ner': 2.308499417969529e-08}\n",
      "Starting iteration73\n",
      "Losses {'ner': 1.9184258175313183e-08}\n",
      "Starting iteration74\n",
      "Losses {'ner': 2.2241424847254784e-10}\n",
      "Starting iteration75\n",
      "Losses {'ner': 1.9589511819399657e-08}\n",
      "Starting iteration76\n",
      "Losses {'ner': 2.239501428129194e-11}\n",
      "Starting iteration77\n",
      "Losses {'ner': 5.451339093816972e-09}\n",
      "Starting iteration78\n",
      "Losses {'ner': 1.5421452310553687e-12}\n",
      "Starting iteration79\n",
      "Losses {'ner': 2.655001790354048e-10}\n",
      "Starting iteration80\n",
      "Losses {'ner': 6.479532632370514e-11}\n",
      "Starting iteration81\n",
      "Losses {'ner': 4.3489483521995944e-10}\n",
      "Starting iteration82\n",
      "Losses {'ner': 2.3553768372021896e-09}\n",
      "Starting iteration83\n",
      "Losses {'ner': 7.698311823797549e-10}\n",
      "Starting iteration84\n",
      "Losses {'ner': 1.4179398377352328e-10}\n",
      "Starting iteration85\n",
      "Losses {'ner': 1.1985250580330224e-08}\n",
      "Starting iteration86\n",
      "Losses {'ner': 3.396271415710559e-11}\n",
      "Starting iteration87\n",
      "Losses {'ner': 5.809694449641641e-09}\n",
      "Starting iteration88\n",
      "Losses {'ner': 3.51704786288195e-10}\n",
      "Starting iteration89\n",
      "Losses {'ner': 1.0666985494679245e-11}\n",
      "Starting iteration90\n",
      "Losses {'ner': 2.4118146522245538e-09}\n",
      "Starting iteration91\n",
      "Losses {'ner': 4.973507186336739e-08}\n",
      "Starting iteration92\n",
      "Losses {'ner': 2.7927975704708604e-10}\n",
      "Starting iteration93\n",
      "Losses {'ner': 1.5491378699820995e-09}\n",
      "Starting iteration94\n",
      "Losses {'ner': 9.986628941159388e-12}\n",
      "Starting iteration95\n",
      "Losses {'ner': 5.478587256239729e-08}\n",
      "Starting iteration96\n",
      "Losses {'ner': 7.975213144187042e-10}\n",
      "Starting iteration97\n",
      "Losses {'ner': 9.568753541815127e-12}\n",
      "Starting iteration98\n",
      "Losses {'ner': 4.800812703041835e-10}\n",
      "Starting iteration99\n",
      "Losses {'ner': 1.3768719085463488e-10}\n",
      "Entities []\n",
      "Tokens [('Yes', '', 2), ('.', '', 2), ('Can', '', 2), ('you', '', 2), ('please', '', 2), ('search', '', 2), ('for', '', 2), ('an', '', 2), ('attraction', '', 2), ('in', '', 2), ('the', '', 2), ('type', '', 2), ('of', '', 2), ('college', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('Is', '', 2), ('one', '', 2), ('of', '', 2), ('them', '', 2), ('in', '', 2), ('the', '', 2), ('cheap', '', 2), ('price', '', 2), ('range', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('not', '', 2), ('really', '', 2), ('but', '', 2), ('i', '', 2), ('need', '', 2), ('it', '', 2), ('for', '', 2), ('3', '', 2), ('people', '', 2)]\n",
      "Entities []\n",
      "Tokens [('Hello', '', 2), (',', '', 2), ('I', '', 2), ('am', '', 2), ('looking', '', 2), ('for', '', 2), ('a', '', 2), ('cheap', '', 2), ('place', '', 2), ('to', '', 2), ('dine', '', 2), ('in', '', 2), ('the', '', 2), ('centre', '', 2)]\n",
      "Entities []\n",
      "Tokens [('Ok', '', 2), (',', '', 2), ('I', '', 2), ('am', '', 2), ('also', '', 2), ('looking', '', 2), ('for', '', 2), ('a', '', 2), ('train', '', 2), ('from', '', 2), ('Cambridge', '', 2), ('to', '', 2), ('Bishops', '', 2), ('Stortford', '', 2), ('.', '', 2)]\n",
      "Entities []\n",
      "Tokens [('Yes', '', 2), ('.', '', 2), ('City', '', 2), ('Centre', '', 2), ('North', '', 2), ('B', '', 2), ('and', '', 2), ('B', '', 2), ('is', '', 2), ('a', '', 2), ('guesthouse', '', 2), ('in', '', 2), ('the', '', 2), ('north', '', 2), ('side', '', 2), ('of', '', 2), ('town', '', 2), (',', '', 2), ('that', '', 2), ('has', '', 2), ('both', '', 2), ('free', '', 2), ('internet', '', 2), ('and', '', 2), ('parking', '', 2), ('.', '', 2), ('Do', '', 2), ('you', '', 2), ('want', '', 2), ('to', '', 2), ('book', '', 2), ('a', '', 2), ('room', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('Yes', '', 2), ('I', '', 2), ('would', '', 2), ('like', '', 2), ('to', '', 2), ('book', '', 2), ('the', '', 2), ('train', '', 2), ('for', '', 2), ('4', '', 2), ('people', '', 2), ('and', '', 2), ('I', '', 2), (\"'ll\", '', 2), ('need', '', 2), ('the', '', 2), ('reference', '', 2), ('number', '', 2), ('please', '', 2), ('.', '', 2)]\n",
      "Entities []\n",
      "Tokens [('I', '', 2), (\"'m\", '', 2), ('looking', '', 2), ('for', '', 2), ('a', '', 2), ('Mediterranean', '', 2), ('restaurant', '', 2), ('near', '', 2), ('the', '', 2), ('centre', '', 2), ('of', '', 2), ('town', '', 2), ('.', '', 2)]\n",
      "Entities [('3 nights', 'hotel-book-stay')]\n",
      "Tokens [('3', 'hotel-book-stay', 3), ('nights', 'hotel-book-stay', 1), (',', '', 2), ('3', '', 2), ('people', '', 2), (',', '', 2), ('please', '', 2), ('.', '', 2)]\n",
      "Entities []\n",
      "Tokens [('I', '', 2), ('would', '', 2), ('like', '', 2), ('to', '', 2), ('leave', '', 2), ('Corpus', '', 2), ('Christi', '', 2), ('College', '', 2), ('in', '', 2), ('enough', '', 2), ('time', '', 2), ('to', '', 2), ('arrive', '', 2), ('at', '', 2), ('the', '', 2), ('restaurant', '', 2), ('at', '', 2), ('the', '', 2), ('booked', '', 2), ('time', '', 2), ('of', '', 2), ('11:30', '', 2), ('.', '', 2)]\n",
      "Entities []\n",
      "Tokens [('Both', '', 2), ('offer', '', 2), ('free', '', 2), ('parking', '', 2), ('and', '', 2), ('free', '', 2), ('wifi', '', 2), ('.', '', 2), ('The', '', 2), ('Alexander', '', 2), ('B&B', '', 2), ('is', '', 2), ('4', '', 2), ('star', '', 2), ('rated', '', 2), ('.', '', 2), ('The', '', 2), ('El', '', 2), ('Shaddai', '', 2), ('has', '', 2), ('a', '', 2), ('0', '', 2), ('rating', '', 2), ('.', '', 2)]\n",
      "Entities []\n",
      "Tokens [('Thanks', '', 2), ('.', '', 2), ('I', '', 2), ('also', '', 2), ('need', '', 2), ('a', '', 2), ('cheap', '', 2), ('place', '', 2), ('to', '', 2), ('stay', '', 2), ('in', '', 2), ('the', '', 2), ('center', '', 2), ('.', '', 2)]\n",
      "Entities []\n",
      "Tokens [('Do', '', 2), ('they', '', 2), ('have', '', 2), ('free', '', 2), ('parking', '', 2), ('?', '', 2), ('If', '', 2), ('so', '', 2), (',', '', 2), ('please', '', 2), ('reserve', '', 2), ('a', '', 2), ('room', '', 2), ('for', '', 2), ('Tuesday', '', 2), ('for', '', 2), ('7', '', 2), ('people', '', 2), (',', '', 2), ('4', '', 2), ('nights', '', 2), ('.', '', 2)]\n",
      "Entities []\n",
      "Tokens [('Is', '', 2), ('an', '', 2), ('entrance', '', 2), ('fee', '', 2), ('okay', '', 2), ('?', '', 2), ('If', '', 2), ('so', '', 2), (',', '', 2), ('the', '', 2), ('corpus', '', 2), ('christi', '', 2), ('college', '', 2), ('located', '', 2), ('at', '', 2), ('king', '', 2), (\"'s\", '', 2), ('parade', '', 2), ('.', '', 2), ('Fee', '', 2), ('is', '', 2), ('2', '', 2), ('pounds', '', 2), ('.', '', 2), ('Would', '', 2), ('you', '', 2), ('like', '', 2), ('the', '', 2), ('phone', '', 2), ('number', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('I', '', 2), ('would', '', 2), ('like', '', 2), ('a', '', 2), ('taxi', '', 2), ('from', '', 2), ('the', '', 2), ('hotel', '', 2), ('to', '', 2), ('the', '', 2), ('restaurant', '', 2), ('.', '', 2), ('I', '', 2), ('would', '', 2), ('like', '', 2), ('to', '', 2), ('arrive', '', 2), ('by', '', 2), ('14:45', '', 2), ('.', '', 2), ('I', '', 2), ('would', '', 2), ('like', '', 2), ('the', '', 2), ('contact', '', 2), ('number', '', 2), ('and', '', 2), ('car', '', 2), ('type', '', 2)]\n",
      "Entities []\n",
      "Tokens [('There', '', 2), ('are', '', 2), ('five', '', 2), ('to', '', 2), ('choose', '', 2), ('from', '', 2), ('.', '', 2), ('Would', '', 2), ('you', '', 2), ('like', '', 2), ('moderate', '', 2), ('or', '', 2), ('expensive', '', 2), ('price', '', 2), ('point', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('TR2630', '', 2), ('leaves', '', 2), ('at', '', 2), ('17:29', '', 2), ('.', '', 2), ('Would', '', 2), ('you', '', 2), ('like', '', 2), ('for', '', 2), ('me', '', 2), ('to', '', 2), ('book', '', 2), ('the', '', 2), ('train', '', 2), ('for', '', 2), ('you', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('Great', '', 2), (',', '', 2), ('could', '', 2), ('I', '', 2), ('book', '', 2), ('a', '', 2), ('table', '', 2), ('of', '', 2), ('5', '', 2), ('for', '', 2), ('11:30', '', 2), ('on', '', 2), ('wednesday', '', 2), ('?', '', 2), ('If', '', 2), ('so', '', 2), (',', '', 2), ('please', '', 2), ('provide', '', 2), ('me', '', 2), ('with', '', 2), ('a', '', 2), ('reference', '', 2), ('number', '', 2)]\n",
      "Entities []\n",
      "Tokens [('I', '', 2), (\"'ve\", '', 2), ('got', '', 2), ('three', '', 2), ('that', '', 2), ('fit', '', 2), ('that', '', 2), ('bill', '', 2), ('...', '', 2), ('the', '', 2), ('gardenia', '', 2), (',', '', 2), ('la', '', 2), ('mimosa', '', 2), (',', '', 2), ('and', '', 2), ('shiraz', '', 2), ('.', '', 2), (' ', '', 2), ('Do', '', 2), ('you', '', 2), ('have', '', 2), ('a', '', 2), ('preference', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('I', '', 2), (\"'ll\", '', 2), ('be', '', 2), ('leaving', '', 2), ('Monday', '', 2), ('after', '', 2), ('15:30', '', 2), ('.', '', 2)]\n",
      "Entities []\n",
      "Tokens [('I', '', 2), (\"'m\", '', 2), ('looking', '', 2), ('for', '', 2), ('a', '', 2), ('place', '', 2), ('to', '', 2), ('stay', '', 2), ('in', '', 2), ('Cambridge', '', 2), ('.', '', 2), ('It', '', 2), ('should', '', 2), ('include', '', 2), ('free', '', 2), ('wifi', '', 2), ('and', '', 2), ('be', '', 2), ('a', '', 2), ('3', '', 2), ('star', '', 2), ('.', '', 2), (' ', '', 2), ('Can', '', 2), ('you', '', 2), ('help', '', 2), ('me', '', 2), ('please', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('Yes', '', 2), ('for', '', 2), ('3', '', 2), ('at', '', 2), ('14:45', '', 2), ('wednesday', '', 2), (',', '', 2), ('can', '', 2), ('I', '', 2), ('get', '', 2), ('the', '', 2), ('reference', '', 2), ('number', '', 2), ('too', '', 2), ('please', '', 2)]\n",
      "Entities []\n",
      "Tokens [('I', '', 2), ('have', '', 2), ('the', '', 2), ('gonville', '', 2), ('hotel', '', 2), ('.', '', 2), ('It', '', 2), ('is', '', 2), ('expensive', '', 2), ('.', '', 2), ('Would', '', 2), ('you', '', 2), ('like', '', 2), ('me', '', 2), ('to', '', 2), ('book', '', 2), ('that', '', 2), ('for', '', 2), ('you', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('I', '', 2), ('recommend', '', 2), ('La', '', 2), ('Raza', '', 2), ('-', '', 2), ('fantastic', '', 2), ('(', '', 2), ('and', '', 2), ('cheap', '', 2), ('!', '', 2), (')', '', 2), ('Spanish', '', 2), ('cuisine', '', 2), ('.', '', 2), ('I', '', 2), (\"'d\", '', 2), ('be', '', 2), ('happy', '', 2), ('to', '', 2), ('book', '', 2), ('a', '', 2), ('table', '', 2), ('for', '', 2), ('you', '', 2), (',', '', 2), ('if', '', 2), ('you', '', 2), ('like', '', 2), ('.', '', 2)]\n",
      "Entities []\n",
      "Tokens [('I', '', 2), ('am', '', 2), ('looking', '', 2), ('for', '', 2), ('info', '', 2), ('about', '', 2), ('a', '', 2), ('hotel', '', 2), ('called', '', 2), ('city', '', 2), ('centre', '', 2), ('north', '', 2), ('b', '', 2), ('and', '', 2), ('b.', '', 2), ('Can', '', 2), ('you', '', 2), ('help', '', 2), ('?', '', 2)]\n",
      "Saved model to output_dir2\n"
     ]
    }
   ],
   "source": [
    "output_dir2 = (\"output_dir2\")\n",
    "def main_train(model=None, output_dir=r'model', n_iter=100):\n",
    "    \"\"\"Load the model, set up the pipeline and train the entity recognizer.\"\"\"\n",
    "    if model is not None:\n",
    "        nlp = spacy.load(model)  # load existing spaCy model\n",
    "        print(\"Loaded model '%s'\" % model)\n",
    "    else:\n",
    "        nlp = spacy.blank(\"en\")  # create blank Language class\n",
    "        print(\"Created blank 'en' model\")\n",
    "\n",
    "    # create the built-in pipeline components and add them to the pipeline\n",
    "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "    if 'ner' not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe('ner')\n",
    "        nlp.add_pipe(ner, last=True)\n",
    "\n",
    "    # otherwise, get it so we can add labels\n",
    "    else:\n",
    "        ner = nlp.get_pipe(\"ner\")\n",
    "\n",
    "    # add labels\n",
    "    for _, annotations in Train_data:\n",
    "         for ent in annotations.get('entities'):\n",
    "            ner.add_label(ent[2])\n",
    "    #for i in my_ent:\n",
    "     #   ner.add_label(i)\n",
    "\n",
    "    # get names of other pipes to disable them during training\n",
    "    #other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "    #with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "        # reset and initialize the weights randomly – but only if we're\n",
    "        # training a new model\n",
    "    if model is None:\n",
    "        nlp.begin_training()\n",
    "    else:\n",
    "        nlp.resume_training()\n",
    "    #if model is None:\n",
    "     #   optimizer = nlp.begin_training()\n",
    "    #else:\n",
    "     #   optimizer = nlp.entity.create_optimizer()\n",
    "    \n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "\n",
    "        for itn in range(n_iter):\n",
    "            print(\"Starting iteration\" + str(itn))\n",
    "            random.shuffle(Train_data)\n",
    "            losses = {}\n",
    "            # batch up the examples using spaCy's minibatch\n",
    "            batches = minibatch(Train_data, size=compounding(4.0, 32.0, 1.001))\n",
    "            for batch in batches:\n",
    "                texts, annotations = zip(*batch)\n",
    "                nlp.update(\n",
    "                texts,  # batch of texts\n",
    "                annotations,  # batch of annotations\n",
    "                drop=0.3,  # dropout - make it harder to memorise data\n",
    "                losses=losses,\n",
    "                )\n",
    "                \n",
    "            print(\"Losses\", losses)\n",
    "    new_model=nlp\n",
    "    # test the trained model\n",
    "    for text, _ in Train_data:\n",
    "        doc = nlp(text)\n",
    "        print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n",
    "        print(\"Tokens\", [(t.text, t.ent_type_, t.ent_iob) for t in doc])\n",
    "\n",
    "    # save model to output directory\n",
    "    #if output_dir2 is not None:\n",
    "     #   output_dir2 = Path(output_dir2)\n",
    "      #  if not output_dir2.exists():\n",
    "       #     output_dir2.mkdir()\n",
    "    nlp.to_disk(output_dir2)\n",
    "    print(\"Saved model to\", output_dir2)\n",
    "main_train(model=None, output_dir=r'model', n_iter=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(nlp):\n",
    "    texts = [\n",
    "        \"Yes I would like to book the train for 4 people and I'll need the reference number please.\",\n",
    "        \"I've got three that fit that bill... the gardenia, la mimosa, and shiraz.  Do you have a preference?\",\n",
    "        \"Great, could I book a table of 5 for 11:30 on wednesday?\",\n",
    "    ]\n",
    "    docs = nlp.pipe(texts)\n",
    "    for doc in docs:\n",
    "        print(doc.text)\n",
    "        print([(t.text, t.dep_, t.head.text) for t in doc if t.dep_ != \"-\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes I would like to book the train for 4 people and I'll need the reference number please.\n",
      "[('Yes', 'intj', 'like'), ('I', 'nsubj', 'like'), ('would', 'aux', 'like'), ('like', 'ROOT', 'like'), ('to', 'aux', 'book'), ('book', 'xcomp', 'like'), ('the', 'det', 'train'), ('train', 'dobj', 'book'), ('for', 'prep', 'book'), ('4', 'nummod', 'people'), ('people', 'pobj', 'for'), ('and', 'cc', 'like'), ('I', 'nsubj', 'need'), (\"'ll\", 'aux', 'need'), ('need', 'conj', 'like'), ('the', 'det', 'number'), ('reference', 'compound', 'number'), ('number', 'dobj', 'need'), ('please', 'intj', 'need'), ('.', 'punct', 'need')]\n",
      "I've got three that fit that bill... the gardenia, la mimosa, and shiraz.  Do you have a preference?\n",
      "[('I', 'nsubj', 'got'), (\"'ve\", 'aux', 'got'), ('got', 'ROOT', 'got'), ('three', 'dobj', 'got'), ('that', 'nsubj', 'fit'), ('fit', 'relcl', 'three'), ('that', 'det', 'bill'), ('bill', 'dobj', 'fit'), ('...', 'punct', 'got'), ('the', 'det', 'gardenia'), ('gardenia', 'ROOT', 'gardenia'), (',', 'punct', 'gardenia'), ('la', 'compound', 'mimosa'), ('mimosa', 'appos', 'gardenia'), (',', 'punct', 'mimosa'), ('and', 'cc', 'mimosa'), ('shiraz', 'conj', 'mimosa'), ('.', 'punct', 'gardenia'), (' ', '', '.'), ('Do', 'aux', 'have'), ('you', 'nsubj', 'have'), ('have', 'ROOT', 'have'), ('a', 'det', 'preference'), ('preference', 'dobj', 'have'), ('?', 'punct', 'have')]\n",
      "Great, could I book a table of 5 for 11:30 on wednesday?\n",
      "[('Great', 'advmod', 'book'), (',', 'punct', 'book'), ('could', 'aux', 'book'), ('I', 'nsubj', 'book'), ('book', 'ROOT', 'book'), ('a', 'det', 'table'), ('table', 'dobj', 'book'), ('of', 'prep', 'table'), ('5', 'pobj', 'of'), ('for', 'prep', 'book'), ('11:30', 'pobj', 'for'), ('on', 'prep', 'book'), ('wednesday', 'pobj', 'on'), ('?', 'punct', 'book')]\n"
     ]
    }
   ],
   "source": [
    "test_model(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from output_dir2\n",
      "Entities [('3 nights', 'hotel-book-stay')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    3 nights\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">hotel-book-stay</span>\n",
       "</mark>\n",
       ", 3 people, please.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Loading from\", output_dir2)\n",
    "nlp2 = spacy.load(output_dir2)\n",
    "doc = nlp2(\"3 nights, 3 people, please.\")\n",
    "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n",
    "displacy.render(doc,  style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from output_dir2\n",
      "Entities []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/runpy.py:184: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Do they have free parking? If so, please reserve a room for Tuesday for 7 people, 4 nights.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Loading from\", output_dir2)\n",
    "nlp2 = spacy.load(output_dir2)\n",
    "doc = nlp2(\"Do they have free parking? If so, please reserve a room for Tuesday for 7 people, 4 nights.\")\n",
    "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n",
    "displacy.render(doc,  style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from output_dir2\n",
      "Entities []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/runpy.py:184: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I want to reserve 4 nights.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Loading from\", output_dir2)\n",
    "nlp2 = spacy.load(output_dir2)\n",
    "doc = nlp2(\"I want to reserve 4 nights.\")\n",
    "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n",
    "displacy.render(doc,  style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'taxi': {'semi': {'arriveBy': '', 'destination': '', 'leaveAt': '', 'departure': ''}, 'book': {'booked': []}}, 'attraction': {'semi': {'name': '', 'area': '', 'type': ''}, 'book': {'booked': []}}, 'hospital': {'semi': {'department': ''}, 'book': {'booked': []}}, 'police': {'semi': {}, 'book': {'booked': []}}, 'restaurant': {'semi': {'name': 'not mentioned', 'food': 'mexican', 'area': 'not mentioned', 'pricerange': 'expensive'}, 'book': {'time': '', 'day': '', 'people': '', 'booked': []}}, 'bus': {'semi': {'arriveBy': '', 'destination': '', 'leaveAt': '', 'departure': '', 'day': ''}, 'book': {'people': '', 'booked': []}}, 'hotel': {'semi': {'name': '', 'area': '', 'pricerange': '', 'type': '', 'stars': '', 'parking': '', 'internet': ''}, 'book': {'day': '', 'stay': '', 'people': '', 'booked': []}}, 'train': {'semi': {'arriveBy': '', 'destination': '', 'leaveAt': '', 'departure': '', 'day': ''}, 'book': {'people': '', 'booked': []}}}\n",
      "{'taxi': {'semi': {'arriveBy': '', 'destination': '', 'leaveAt': '', 'departure': ''}, 'book': {'booked': []}}, 'attraction': {'semi': {'name': '', 'area': '', 'type': ''}, 'book': {'booked': []}}, 'hospital': {'semi': {'department': ''}, 'book': {'booked': []}}, 'police': {'semi': {}, 'book': {'booked': []}}, 'restaurant': {'semi': {'name': 'chiquito restaurant bar', 'food': 'mexican', 'area': 'not mentioned', 'pricerange': 'expensive'}, 'book': {'time': '', 'day': '', 'people': '', 'booked': []}}, 'bus': {'semi': {'arriveBy': '', 'destination': '', 'leaveAt': '', 'departure': '', 'day': ''}, 'book': {'people': '', 'booked': []}}, 'hotel': {'semi': {'name': '', 'area': '', 'pricerange': '', 'type': '', 'stars': '', 'parking': '', 'internet': ''}, 'book': {'day': '', 'stay': '', 'people': '', 'booked': []}}, 'train': {'semi': {'arriveBy': '', 'destination': '', 'leaveAt': '', 'departure': '', 'day': ''}, 'book': {'people': '', 'booked': []}}}\n",
      "{'taxi': {'semi': {'arriveBy': '', 'destination': '', 'leaveAt': '', 'departure': ''}, 'book': {'booked': []}}, 'attraction': {'semi': {'name': '', 'area': '', 'type': ''}, 'book': {'booked': []}}, 'hospital': {'semi': {'department': ''}, 'book': {'booked': []}}, 'police': {'semi': {}, 'book': {'booked': []}}, 'restaurant': {'semi': {'name': 'chiquito restaurant bar', 'food': 'mexican', 'area': 'not mentioned', 'pricerange': 'expensive'}, 'book': {'time': '14:30', 'day': 'friday', 'people': '5', 'booked': [{'reference': 'OZZGLCVB', 'name': 'chiquito restaurant bar'}]}}, 'bus': {'semi': {'arriveBy': '', 'destination': '', 'leaveAt': '', 'departure': '', 'day': ''}, 'book': {'people': '', 'booked': []}}, 'hotel': {'semi': {'name': '', 'area': '', 'pricerange': '', 'type': '', 'stars': '', 'parking': '', 'internet': ''}, 'book': {'day': '', 'stay': '', 'people': '', 'booked': []}}, 'train': {'semi': {'arriveBy': '', 'destination': '', 'leaveAt': '', 'departure': '', 'day': ''}, 'book': {'people': '', 'booked': []}}}\n",
      "{'taxi': {'semi': {'arriveBy': '', 'destination': '', 'leaveAt': '', 'departure': ''}, 'book': {'booked': []}}, 'attraction': {'semi': {'name': '', 'area': '', 'type': ''}, 'book': {'booked': []}}, 'hospital': {'semi': {'department': ''}, 'book': {'booked': []}}, 'police': {'semi': {}, 'book': {'booked': []}}, 'restaurant': {'semi': {'name': 'chiquito restaurant bar', 'food': 'mexican', 'area': 'not mentioned', 'pricerange': 'expensive'}, 'book': {'time': '14:30', 'day': 'friday', 'people': '5', 'booked': [{'reference': 'OZZGLCVB', 'name': 'chiquito restaurant bar'}]}}, 'bus': {'semi': {'arriveBy': '', 'destination': '', 'leaveAt': '', 'departure': '', 'day': ''}, 'book': {'people': '', 'booked': []}}, 'hotel': {'semi': {'name': '', 'area': '', 'pricerange': '', 'type': '', 'stars': '', 'parking': '', 'internet': ''}, 'book': {'day': '', 'stay': '', 'people': '', 'booked': []}}, 'train': {'semi': {'arriveBy': '', 'destination': '', 'leaveAt': '', 'departure': '', 'day': ''}, 'book': {'people': '', 'booked': []}}}\n",
      "{'taxi': {'semi': {'arriveBy': '', 'destination': '', 'leaveAt': '', 'departure': ''}, 'book': {'booked': []}}, 'attraction': {'semi': {'name': '', 'area': '', 'type': ''}, 'book': {'booked': []}}, 'hospital': {'semi': {'department': ''}, 'book': {'booked': []}}, 'police': {'semi': {}, 'book': {'booked': []}}, 'restaurant': {'semi': {'name': 'chiquito restaurant bar', 'food': 'mexican', 'area': 'not mentioned', 'pricerange': 'expensive'}, 'book': {'time': '14:30', 'day': 'friday', 'people': '5', 'booked': [{'reference': 'OZZGLCVB', 'name': 'chiquito restaurant bar'}]}}, 'bus': {'semi': {'arriveBy': '', 'destination': '', 'leaveAt': '', 'departure': '', 'day': ''}, 'book': {'people': '', 'booked': []}}, 'hotel': {'semi': {'name': 'not mentioned', 'area': 'not mentioned', 'pricerange': 'not mentioned', 'type': 'hotel', 'stars': '4', 'parking': 'not mentioned', 'internet': 'not mentioned'}, 'book': {'day': '', 'stay': '', 'people': '', 'booked': []}}, 'train': {'semi': {'arriveBy': '', 'destination': '', 'leaveAt': '', 'departure': '', 'day': ''}, 'book': {'people': '', 'booked': []}}}\n",
      "{'taxi': {'semi': {'arriveBy': '', 'destination': '', 'leaveAt': '', 'departure': ''}, 'book': {'booked': []}}, 'attraction': {'semi': {'name': '', 'area': '', 'type': ''}, 'book': {'booked': []}}, 'hospital': {'semi': {'department': ''}, 'book': {'booked': []}}, 'police': {'semi': {}, 'book': {'booked': []}}, 'restaurant': {'semi': {'name': 'chiquito restaurant bar', 'food': 'mexican', 'area': 'not mentioned', 'pricerange': 'expensive'}, 'book': {'time': '14:30', 'day': 'friday', 'people': '5', 'booked': [{'reference': 'OZZGLCVB', 'name': 'chiquito restaurant bar'}]}}, 'bus': {'semi': {'arriveBy': '', 'destination': '', 'leaveAt': '', 'departure': '', 'day': ''}, 'book': {'people': '', 'booked': []}}, 'hotel': {'semi': {'name': 'not mentioned', 'area': 'dontcare', 'pricerange': 'expensive', 'type': 'hotel', 'stars': '4', 'parking': 'not mentioned', 'internet': 'not mentioned'}, 'book': {'day': '', 'stay': '', 'people': '', 'booked': []}}, 'train': {'semi': {'arriveBy': '', 'destination': '', 'leaveAt': '', 'departure': '', 'day': ''}, 'book': {'people': '', 'booked': []}}}\n",
      "{'taxi': {'semi': {'arriveBy': '', 'destination': '', 'leaveAt': '', 'departure': ''}, 'book': {'booked': []}}, 'attraction': {'semi': {'name': '', 'area': '', 'type': ''}, 'book': {'booked': []}}, 'hospital': {'semi': {'department': ''}, 'book': {'booked': []}}, 'police': {'semi': {}, 'book': {'booked': []}}, 'restaurant': {'semi': {'name': 'chiquito restaurant bar', 'food': 'mexican', 'area': 'not mentioned', 'pricerange': 'expensive'}, 'book': {'time': '14:30', 'day': 'friday', 'people': '5', 'booked': [{'reference': 'OZZGLCVB', 'name': 'chiquito restaurant bar'}]}}, 'bus': {'semi': {'arriveBy': '', 'destination': '', 'leaveAt': '', 'departure': '', 'day': ''}, 'book': {'people': '', 'booked': []}}, 'hotel': {'semi': {'name': 'huntingdon marriott hotel', 'area': 'dontcare', 'pricerange': 'expensive', 'type': 'hotel', 'stars': '4', 'parking': 'not mentioned', 'internet': 'not mentioned'}, 'book': {'day': 'friday', 'stay': '2', 'people': '5', 'booked': [{'reference': 'Y79YGBO7', 'name': 'huntingdon marriott hotel'}]}}, 'train': {'semi': {'arriveBy': '', 'destination': '', 'leaveAt': '', 'departure': '', 'day': ''}, 'book': {'people': '', 'booked': []}}}\n",
      "{'taxi': {'semi': {'arriveBy': '', 'destination': '', 'leaveAt': '', 'departure': ''}, 'book': {'booked': []}}, 'attraction': {'semi': {'name': '', 'area': '', 'type': ''}, 'book': {'booked': []}}, 'hospital': {'semi': {'department': ''}, 'book': {'booked': []}}, 'police': {'semi': {}, 'book': {'booked': []}}, 'restaurant': {'semi': {'name': 'chiquito restaurant bar', 'food': 'mexican', 'area': 'not mentioned', 'pricerange': 'expensive'}, 'book': {'time': '14:30', 'day': 'friday', 'people': '5', 'booked': [{'reference': 'OZZGLCVB', 'name': 'chiquito restaurant bar'}]}}, 'bus': {'semi': {'arriveBy': '', 'destination': '', 'leaveAt': '', 'departure': '', 'day': ''}, 'book': {'people': '', 'booked': []}}, 'hotel': {'semi': {'name': 'huntingdon marriott hotel', 'area': 'dontcare', 'pricerange': 'expensive', 'type': 'hotel', 'stars': '4', 'parking': 'not mentioned', 'internet': 'not mentioned'}, 'book': {'day': 'friday', 'stay': '2', 'people': '5', 'booked': [{'reference': 'Y79YGBO7', 'name': 'huntingdon marriott hotel'}]}}, 'train': {'semi': {'arriveBy': '', 'destination': '', 'leaveAt': '', 'departure': '', 'day': ''}, 'book': {'people': '', 'booked': []}}}\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, examples):\n",
    "    scorer = Scorer()\n",
    "    for text, metadata in Train_data:\n",
    "        #print(text)\n",
    "        doc_gold_text = model.make_doc(text)\n",
    "        gold = GoldParse(doc_gold_text, entities=metadata['entities'])\n",
    "        pred_value = model(text)\n",
    "        scorer.score(pred_value, gold)\n",
    "    return scorer.scores\n",
    "test_data=[]\n",
    "x=[]\n",
    "object_2 = list(dict_json_weighted.keys())[6]\n",
    "#for i in dict_json_weighted[object_2]['goal']:\n",
    "#    if i!='message':\n",
    "#        if dict_json_weighted[object_2]['goal'][i] !={}:\n",
    "#            print(\"****** \"+i+\" ******\")\n",
    "#            for j in (dict_json_weighted[object_2]['goal'][i]):\n",
    "#                if dict_json_weighted[object_2]['goal'][i][j] not in ['fail_info', {}, False]:\n",
    "#                    print(\"°\"+j)\n",
    "#                    print(dict_json_weighted[object_2]['goal'][i][j])\n",
    "                    #x.append({j ,(dict_json_weighted[object_2]['goal'][i][j])})\n",
    "            \n",
    "for i in range(len(dict_json_weighted[object_2]['log'])):\n",
    "    #print(dict_json_weighted[object_2]['log'][i])\n",
    "    #test_text=test_text+\"\\n\"+dict_json_weighted[object_2]['log'][i]['text']\n",
    "    #test_annot=test_annot+\"\\n\"+str(dict_json_weighted[object_2]['log'][i]['metadata'])\n",
    "    if (dict_json_weighted[object_2]['log'][i]['metadata'])!={} :\n",
    "        test_data.append({dict_json_weighted[object_2]['log'][i]['text'], str(dict_json_weighted[object_2]['log'][i]['metadata'])})\n",
    "        print(dict_json_weighted[object_2]['log'][i]['metadata'])\n",
    "#print(test_data)\n",
    "test_result = evaluate(new_model, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
